---
title: 机器学习项目技术选型与实践概览
date: 2026-01-22 09:00:00
categories: [AI, ML]
tags: [AI, ML]
image:
  path: /assets/img/posts/common/ml.jpg
---

# 机器学习任务类型、应用场景与技术选型

> 系统梳理机器学习的任务类型（分类、回归、聚类等）、典型应用场景（表格、文本、图像、语音），各场景下的主流技术路线，以及传统机器学习与深度学习的区别与选型依据。从第一性原理出发，理解"做什么任务、用什么数据、选什么技术"。

## 目录

1. [机器学习有哪些任务类型？](#1-机器学习有哪些任务类型)
2. [任务类型与损失、评估](#2-任务类型与损失评估)
3. [应用场景与主流技术](#3-应用场景与主流技术)
4. [传统机器学习与深度学习的区别](#4-传统机器学习与深度学习的区别)
5. [如何选型？](#5-如何选型)
6. [总结](#6-总结)

---

## 1. 机器学习有哪些任务类型？

### 1.1 按「有没有标签」划分

**有监督学习（Supervised）**：有标签，学习「输入 → 标签」的映射。

- **分类（Classification）**：标签离散。
  - **二分类**：是/否（如垃圾邮件、欺诈检测）。
  - **多分类**：多选一（如图像类别：猫/狗/鸟）。
  - **多标签分类**：多选多（如文档标签：科技+AI+深度学习）。
- **回归（Regression）**：标签连续。
  - **字面意思**："回归"原指"回到平均值"，统计学中用于描述变量间关系。
  - **机器学习含义**：预测连续数值（如房价、销量、点击率、温度）。
  - **为什么需要标签连续？**
    - **业务需求**：很多问题需要预测具体数值，而非类别。例如：房价是多少（不是"贵/便宜"），销量是多少（不是"高/低"）。
    - **数学本质**：连续值可以表示任意精度，适合描述"程度"和"大小"；离散类别只能表示"是/否"或有限选项。
    - **与分类的区别**：分类输出"类别"（如"猫/狗"），回归输出"数值"（如"25.3度"）。

**无监督学习（Unsupervised）**：无标签，从数据本身找结构。

- **聚类（Clustering）**：把样本分成若干组（如用户分群、异常群发现）。
- **降维（Dimensionality Reduction）**：压缩特征维度，保留主要信息（如 PCA、t-SNE 可视化）。
- **异常检测（Anomaly Detection）**：找出与多数差异大的样本。

**其他**：半监督（少量标注+大量无标注）、强化学习（通过奖励学习策略）等。

### 1.2 任务类型小结

| 任务       | 输出       | 典型场景         |
|------------|------------|------------------|
| 二分类     | 0/1 或概率 | 垃圾邮件、欺诈   |
| 多分类     | 类别ID     | 图像分类、意图识别 |
| 多标签分类 | 多个类别   | 文档标签、风险多类型 |
| 回归       | 连续值     | 房价、销量、CTR  |
| 聚类       | 簇ID       | 用户分群、新类发现 |
| 异常检测   | 正常/异常  | 入侵检测、故障检测 |
| 排序       | 序关系     | 推荐、搜索排序   |

---

## 2. 任务类型与损失、评估

### 2.1 不同任务常用损失函数

#### 损失函数的作用

**本质**：损失函数衡量模型预测与真实值的差距，是训练时的优化目标。

**作用**：
- **定义优化目标**：告诉模型要"最小化"什么
- **提供梯度方向**：通过求导得到参数更新方向
- **反映拟合程度**：损失越小，说明模型在当前数据上拟合越好

#### 交叉熵（Cross-Entropy）

**定义**：衡量预测概率分布与真实标签分布的差异。

**公式**（二分类）：
```
交叉熵 = -(真实标签 × log(预测概率) + (1-真实标签) × log(1-预测概率))
```

**原理**：
- **为什么用对数？** 预测概率接近0时，log会放大误差，让模型更关注"错得离谱"的样本。
- **为什么用负号？** 概率在[0,1]之间，log为负；加负号后，预测越准，损失越小。
- **本质**：信息论中的"信息量"，衡量两个概率分布的差异。

**例子**：
```
真实标签：1（正类）
预测概率：0.9

交叉熵 = -(1 × log(0.9) + 0 × log(0.1)) = -log(0.9) ≈ 0.105
→ 预测较准，损失较小 ✅

如果预测概率：0.1
交叉熵 = -log(0.1) ≈ 2.3
→ 预测错误，损失较大 ❌
```

**适用**：二分类、多分类、多标签分类。

#### 均方误差（MSE）与平均绝对误差（MAE）

**MSE**：
```
MSE = Σ(预测值 - 真实值)² / n
```
- **原理**：平方放大大误差，对大偏差更敏感。
- **适用**：回归任务，对异常值敏感的场景。

**MAE**：
```
MAE = Σ|预测值 - 真实值| / n
```
- **原理**：线性误差，对所有误差一视同仁。
- **适用**：回归任务，对异常值不敏感的场景。

#### 其他任务的损失函数

- **聚类**：簇内距离和（如 K-Means）、基于密度的目标等。无监督，没有「标准答案」式的损失，但有优化目标。
- **排序**：Pairwise / Listwise 损失（如 Cross-Entropy on pairs、ListNet）。优化相对顺序而非绝对分数。

**要点**：任务类型决定我们**优化什么**（损失函数），进而影响训练目标和模型设计。

### 2.2 评估指标的原理

#### 为什么需要评估指标？

**问题**：损失函数是训练时的优化目标，但业务更关心"准确率""召回率"等直观指标。

**解决**：用评估指标衡量模型在业务目标上的表现。

#### 常用评估指标

**准确率（Accuracy）**：
```
准确率 = 正确预测数 / 总样本数
```
- **原理**：最直观，但类别不平衡时容易误导（如99%都是正类，全预测正类也能有99%准确率）。
- **适用**：类别平衡的二分类、多分类。

**精确率（Precision）与召回率（Recall）**：
```
精确率 = TP / (TP + FP)  # 预测为正的样本中，真正为正的比例
召回率 = TP / (TP + FN)  # 真实为正的样本中，被正确预测的比例
```
- **原理**：
  - **精确率**：关注"预测为正的样本中，有多少是真的正类"（减少误报）。
  - **召回率**：关注"真实为正的样本中，有多少被找出来了"（减少漏报）。
- **适用**：类别不平衡、需要权衡误报与漏报的场景。

**F1 分数（F1 Score）**：
```
F1 = 2 × (精确率 × 召回率) / (精确率 + 召回率)
```
- **原理**：精确率和召回率的调和平均数，平衡两者。
- **为什么用调和平均？** 调和平均对极端值更敏感，只有精确率和召回率都高时，F1才高。
- **适用**：需要平衡精确率和召回率的场景。

**AUC（ROC 曲线下面积）**：
```
AUC = ROC 曲线下的面积
```
- **原理**：衡量模型区分正负样本的能力，不受阈值影响。
- **含义**：随机选一个正样本和一个负样本，模型对正样本的预测概率高于负样本的概率。
- **适用**：二分类，关注排序能力而非绝对概率。

**MAP（Mean Average Precision）**：
- **原理**：多标签/排序任务中，考虑位置的平均精确率。
- **适用**：推荐、检索、多标签分类。

### 2.3 损失与评估指标的关系

- **损失函数**：训练时优化目标，可导、便于梯度下降。
- **评估指标**：业务更关心什么，就选什么（如 F1、AUC、MAP、NDCG）。
- 损失与指标**可以不一致**：例如用交叉熵训练，用 F1 选模型、调参。

---

## 3. 应用场景与主流技术

### 3.1 按数据形态划分的应用场景

| 场景   | 数据形态     | 典型任务       | 主流技术（传统 ML）     | 主流技术（深度学习）       |
|--------|--------------|----------------|--------------------------|----------------------------|
| 表格   | 行=样本,列=特征 | 分类、回归、排序 | 树模型（XGBoost、LightGBM 等） | 深度表格模型（TabNet、Transformer 等） |
| 文本   | 序列/词袋    | 分类、匹配、生成 | 特征 + 线性模型/树模型   | RNN/Transformer、BERT、GPT 等 |
| 图像   | 像素矩阵     | 分类、检测、分割 | 手工特征 + 分类器        | CNN、ViT、Detection/Segmentation 网络 |
| 语音   | 波形/频谱    | 识别、合成、唤醒 | HMM + GMM、传统声学模型  | RNN/Transformer、端到端 ASR、TTS |
| 多模态 | 文本+图像等  | 理解、检索、生成 | 多源特征融合 + 模型      | 多模态 Transformer、CLIP 等 |

### 3.2 表格数据（结构化数据）

**特点**：行是样本，列是特征；数值、类别、时间等混合。

**典型任务**：二分类、多分类、多标签、回归、点击率预估、风控等。

**传统 ML 主流**：

- **树模型**：XGBoost、LightGBM、CatBoost。
- **逻辑回归、线性模型**：可解释、易部署，常与特征工程结合。
- **用途**：中小规模数据、需要可解释性、上线简单时，往往优先考虑。

**深度学习**：

- **TabNet、深度表格模型、Transformer 等**：适合大数据、复杂交互，可解释性通常弱于树模型。

### 3.3 文本（NLP）

**特点**：离散符号、序列结构、长程依赖。

**典型任务**：分类、情感分析、NER、机器翻译、问答、摘要、生成等。

**传统 ML**：

- **特征**：词袋、TF-IDF、n-gram、统计特征。
- **模型**：朴素贝叶斯、SVM、逻辑回归、XGBoost 等。
- **适用**：数据少、任务简单、需要强可解释性时。

**深度学习主流**：

- **RNN/LSTM**：序列建模，逐步被 Transformer 替代。
- **Transformer / BERT / GPT**：预训练 + 微调，成为文本任务主流。
- **适用**：数据充足、任务复杂、追求 SOTA 时。

### 3.4 图像（CV）

**特点**：高维、局部与层次结构、平移/缩放等不变性。

**典型任务**：图像分类、目标检测、语义分割、人脸识别等。

**传统 ML**：

- **特征**：SIFT、HOG、颜色直方图、LBP 等。
- **模型**：SVM、随机森林等。
- **适用**：数据少、任务简单、资源有限时。

**深度学习主流**：

- **CNN**：VGG、ResNet、EfficientNet 等，分类、特征提取。
- **ViT**：基于 Transformer 的图像模型。
- **检测 / 分割**：Faster R-CNN、YOLO、Mask R-CNN、U-Net 等。
- **适用**：数据充足、任务复杂时，几乎成默认选择。

### 3.5 语音

**特点**：时序、高维、信噪比敏感。

**典型任务**：语音识别（ASR）、合成（TTS）、唤醒、声纹等。

**语音处理的原理**：

- **语音信号**：声波是连续的时间序列，需要转换为数字信号（采样、量化）。
- **特征提取**：传统方法提取 MFCC（梅尔频率倒谱系数）、频谱特征等，表示语音的声学特性。
- **时序建模**：语音是序列数据，需要建模时间依赖关系（如"你好"中"你"和"好"的顺序）。
- **声学模型**：学习"声学特征 → 音素/字"的映射。
- **语言模型**：学习"字/词序列"的概率分布，帮助纠正识别错误。

**传统 ML**：

- **HMM + GMM、传统声学模型**：
  - **HMM（隐马尔可夫模型）**：建模语音的时序状态转移（如音素之间的转换）。
  - **GMM（高斯混合模型）**：建模每个状态的声学特征分布。
  - **Pipeline**：特征提取 → 声学模型 → 语言模型 → 解码，步骤多、复杂，逐步被端到端替代。

**深度学习主流**：

- **端到端 ASR**：
  - **CNN+RNN+CTC**：CNN提取特征，RNN建模时序，CTC处理对齐问题（语音长度与文本长度不一致）。
  - **RNN-T、基于 Transformer 的 ASR**：更先进的序列建模，直接学习"语音 → 文本"的映射。
- **TTS（文本转语音）**：Tacotron、VITS 等，学习"文本 → 语音特征 → 声波"的生成过程。
- **适用**：大多数语音产品已以深度学习为主，端到端训练更简单、效果更好。

### 3.6 多模态

**特点**：同时包含文本、图像、语音等，需对齐与融合。

**典型任务**：图文理解、检索、字幕、视觉问答、多模态生成等。

**主流**：多模态 Transformer、CLIP、BLIP 等；传统 ML 多为多源特征拼接 + 传统模型，效果通常不如深度多模态模型。

---

## 4. 传统机器学习与深度学习的区别

### 4.1 从「假设空间」理解

- **传统 ML**：  
  - 依赖**人工特征**：领域知识、统计、规则。  
  - 模型相对简单：线性、树、浅层组合。  
  - 假设空间更小、更可控。

- **深度学习**：  
  - **端到端**：从原始或浅层特征学习层次表示。  
  - 模型复杂：多层非线性、注意力等。  
  - 假设空间大，拟合能力强。

### 4.2 数据量、可解释性、资源

| 维度         | 传统 ML                     | 深度学习                         |
|--------------|-----------------------------|----------------------------------|
| 数据量       | 小、中数据即可有不错效果   | 通常需要大量数据                 |
| 特征         | 强依赖特征工程             | 可自动学习表示，仍可做特征工程   |
| 可解释性     | 树、线性模型等易解释       | 多为黑盒，需 SHAP、注意力等辅助  |
| 计算资源     | CPU 为主，资源需求低       | 常需 GPU，训练与推理成本高       |
| 调参与运维   | 相对简单                   | 超参多、训练不稳定，工程复杂     |

### 4.3 何时更偏向传统 ML？何时更偏向深度学习？

**更偏向传统 ML**：

- 表格数据、样本量有限。
- 重视可解释性、上线简单、迭代快。
- 分类、回归、排序等「经典」任务，且无强烈端到端需求。

**更偏向深度学习**：

- 文本、图像、语音、多模态等非结构化数据。
- 数据量大、追求极致效果。
- 需要端到端建模（如 ASR、机器翻译、图像生成）。

**混合使用**：

- 表格用 XGBoost，文本用 BERT；多模态中既有传统特征也有深度模块。
- 用深度模型做表征，再用传统模型做决策（如 BERT 特征 + XGBoost）。

---

## 5. 如何选型？

### 5.1 按任务选

- **分类 / 回归 / 排序**：先明确二分类、多分类、多标签还是回归，再选损失与模型。
- **聚类 / 异常检测**：无监督，选聚类算法（K-Means、DBSCAN 等）或异常检测方法（如基于距离、密度、孤立森林）。

### 5.2 按数据形态选

- **表格**：树模型（XGBoost 等）优先；数据量巨大再考虑深度表格模型。
- **文本**：
  - **传统 ML**：词袋、TF-IDF 等特征 + 线性模型/树模型。适合数据少、任务简单、需要可解释性的场景。
  - **BERT/Transformer**：
    - **BERT**：双向编码器，通过大规模预训练学习文本表示，然后在下游任务上微调。优势是理解上下文、语义丰富。
    - **Transformer**：基于注意力机制的架构，能捕捉长距离依赖，并行计算效率高。
    - **区别**：传统 ML 依赖人工特征（如词频），BERT/Transformer 能自动学习文本的深层语义表示，适合复杂任务（如理解、生成）。
- **图像**：复杂任务多用 CNN/ViT 等。
- **语音**：以深度学习端到端为主。

### 5.3 按业务约束选

- **可解释性**：树、线性模型、简单规则；深度模型需配合解释工具。
- **延迟与资源**：传统 ML 或小型网络更容易满足；大模型需蒸馏、裁剪、量化。
- **数据与标注**：数据少时优先传统 ML 或预训练 + 微调；数据多时可考虑大规模深度模型。

---

## 6. 总结

- **任务类型**：分类（二分类/多分类/多标签）、回归、聚类、异常检测、排序等，决定**优化目标**（损失）和**评估指标**。
- **应用场景**：表格、文本、图像、语音、多模态，各有一套**主流技术**；表格多用树模型，文本/图像/语音多用深度学习。
- **传统 ML vs 深度学习**：传统 ML 偏少数据、可解释、易部署；深度学习偏大数据、端到端、非结构化。选型时要结合任务、数据形态和业务约束。

理解「任务 → 损失 → 模型」和「数据形态 → 技术路线」，能更清晰地在项目中做技术选型与迭代。
