---
title: 华为昇腾LLM大模型部署和量化
date: 2025-11-05 20:15:00
categories: [AI, 华为昇腾]
tags: [AI, 华为昇腾, LLM部署]
image:
  path: /assets/img/posts/common/hw-ascend.jpg
---

# 华为昇腾LLM大模型部署和量化

## 相关平台
- [华为昇腾首页](https://www.hiascend.com/)
- [魔乐社区-模型、工具、数据集下载](https://modelers.cn/)
- [昇腾开发者社区](https://www.hiascend.com/developer)

## 基础
- [MindIE镜像下载](https://www.hiascend.com/developer/ascendhub/detail/af85b724a7e5469ebd7ea13c3439d48f)
- [MindIE容器启动](https://gitee.com/ascend/ascend-docker-image/tree/dev/mindie#%E5%90%AF%E5%8A%A8%E5%AE%B9%E5%99%A8)

## LLM部署
- [使用MindIE部署QwQ-32B](https://modelers.cn/models/Models_Ecosystem/QwQ-32B)
- [使用MindIE部署DeepSeek-R1](https://gitee.com/ascend/ModelZoo-PyTorch/blob/master/MindIE/LLM/DeepSeek/DeepSeek-R1/README.md)
- 守护进程方式部署模型

    通常模型服务化（暴露http接口等端点）部署配置文件位于`/usr/local/Ascend/mindie/latest/mindie-service/config/config.json`。而改用环境量方式定义配置文件路径，可以灵活切换运行的模型
    ```sh
    export MIES_CONFIG_JSON_PATH=/model/config/qwen2.5-14b.json    
    nohup /usr/local/Ascend/mindie/latest/mindie-service/bin/mindieservice_daemon > /dev/null 2>&1 &
    ```
- [Ascend Deployer昇腾软件工具包使用](https://www.hiascend.com/document/detail/zh/mindcluster/72rc1/deployer/deployerug/deployer_0001.html)

## 量化
- [msmodelslim量化工具安装](https://gitee.com/ascend/msit/tree/master/msmodelslim)
- [量化脚本使用说明](https://www.hiascend.com/document/detail/zh/mindie/100/mindiellm/llmdev/mindie_llm0280.html)
- [Qwen 量化案例](https://gitee.com/ascend/msit/blob/master/msmodelslim/example/Qwen/README.md)

## 学习资源
- [昇腾AI学堂-基于MindIE推理引擎部署DeepSeek R1](https://2b87aad812c94b3392d218f35fa6ca3f.shixizhi.huawei.com/live/replay.htm?actId=o33r63no&liveId=1898981032604999681)
- [昇腾开发者在线课程](https://www.hiascend.com/edu/courses)
- [昇腾开发者在线实验](https://www.hiascend.com/edu/experiment)
- [昇腾认证](https://www.hiascend.com/edu/certification)