---
title: AI大模型文件结构
date: 2025-10-07 22:10:00
categories: [AI, AI基础，大模型]
tags: [AI, AI基础，大模型]
image:
  path: /assets/img/posts/common/AI.jpg
---

# AI大模型文件结构

## 目录
- [概述](#概述)
- [一、单体模型结构（以 BLIP 为例）](#一单体模型结构以-blip-为例)
- [二、Pipeline 模型结构（以 Stable Diffusion 为例）](#二pipeline-模型结构以-stable-diffusion-为例)
- [三、其他复杂模型架构](#三其他复杂模型架构)
- [四、文件类型详解](#四文件类型详解)
- [五、最佳实践](#五最佳实践)

---

## 概述

大模型通常由多个文件组成，这些文件包含了模型的权重参数、配置信息、预处理器设置等。根据模型的复杂度，文件结构可以分为：
- **单体模型**：所有组件在同一目录下（如 BLIP 图生文模型）
- **Pipeline 模型**：由多个子模型组成的复杂架构（如 Stable Diffusion 图生图模型）

---

## 一、单体模型结构（以 BLIP 为例）

### 1.1 完整文件列表

```
blip-image-captioning-base/
├── config.json                      # 模型主配置文件
├── pytorch_model.bin                # PyTorch 模型权重文件
├── tf_model.h5                      # TensorFlow 模型权重文件
├── tokenizer.json                   # 分词器快速版本
├── tokenizer_config.json            # 分词器配置文件
├── vocab.txt                        # 词汇表文件
├── special_tokens_map.json          # 特殊标记映射文件
└── preprocessor_config.json         # 预处理器配置文件
```

### 1.2 核心文件说明

#### 1.2.1 模型权重文件
- **pytorch_model.bin** (944MB)
  - 存储 PyTorch 格式的模型权重参数
  - 包含所有神经网络层的训练权重
  - 使用二进制格式存储，节省空间
  - 必需文件，模型推理时加载

- **tf_model.h5** (944MB)
  - TensorFlow/Keras 格式的模型权重
  - 与 pytorch_model.bin 功能相同，用于不同框架
  - 如果只使用 PyTorch 可以删除此文件

#### 1.2.2 模型配置文件
- **config.json** (4.5KB, 170行)
  - 定义模型架构和超参数
  - 主要内容：
    - `architectures`: 模型架构类型 (如 "BlipForConditionalGeneration")
    - `text_config`: 文本编码器配置
      - `hidden_size`: 隐藏层维度 (768)
      - `num_hidden_layers`: 层数 (12)
      - `num_attention_heads`: 注意力头数量 (12)
      - `vocab_size`: 词汇表大小 (30524)
    - `vision_config`: 视觉编码器配置
      - `image_size`: 输入图像尺寸 (384)
      - `patch_size`: 图像分块大小 (16)
      - `num_channels`: 输入通道数 (3, RGB)
    - `torch_dtype`: 数据类型 (float32)

#### 1.2.3 分词器相关文件
- **tokenizer.json** (695KB, 30672行)
  - 快速分词器（Rust 实现）的完整配置
  - 包含分词规则、合并规则、后处理步骤
  - 用于高性能推理

- **tokenizer_config.json** (506B, 22行)
  - 分词器的配置参数
  - 主要内容：
    - `model_max_length`: 最大序列长度 (512)
    - `tokenizer_class`: 分词器类名 ("BertTokenizer")
    - `do_lower_case`: 是否转小写 (true)
    - 特殊标记定义 (CLS, SEP, PAD, MASK, UNK)

- **vocab.txt** (226KB, 30523行)
  - 词汇表文件，每行一个词
  - 包含所有支持的 token
  - 文本转换为数字 ID 的映射基础

- **special_tokens_map.json** (125B, 8行)
  - 定义特殊标记的映射关系
  - 如 [CLS]（分类标记）、[SEP]（分隔标记）、[PAD]（填充标记）等

#### 1.2.4 预处理器文件
- **preprocessor_config.json** (287B, 18行)
  - 图像预处理配置
  - 主要内容：
    - `do_resize`: 是否调整图像大小 (true)
    - `do_normalize`: 是否归一化 (true)
    - `size`: 目标图像尺寸 (384)
    - `image_mean`: 归一化均值 [0.48, 0.46, 0.41]
    - `image_std`: 归一化标准差 [0.27, 0.26, 0.28]
    - `processor_class`: 处理器类名 ("BlipProcessor")

---

## 二、Pipeline 模型结构（以 Stable Diffusion 为例）

### 2.1 完整目录结构

```
stable-diffusion-v1-5-img2img/
├── model_index.json                 # Pipeline 索引文件
├── v1-5-pruned-emaonly.safetensors # 完整模型权重（SafeTensors 格式）
├── text_encoder/                    # 文本编码器子模块
│   ├── config.json                  # 文本编码器配置
│   └── pytorch_model.bin            # 文本编码器权重
├── tokenizer/                       # 分词器子模块
│   ├── tokenizer_config.json        # 分词器配置
│   ├── vocab.json                   # 词汇表（JSON 格式）
│   └── merges.txt                   # BPE 合并规则
├── unet/                            # UNet 去噪网络子模块
│   ├── config.json                  # UNet 配置
│   └── diffusion_pytorch_model.bin  # UNet 权重
├── vae/                             # 变分自编码器子模块
│   ├── config.json                  # VAE 配置
│   └── diffusion_pytorch_model.bin  # VAE 权重
├── scheduler/                       # 调度器子模块
│   └── scheduler_config.json        # 调度器配置
└── feature_extractor/               # 特征提取器子模块
    └── preprocessor_config.json     # 预处理配置
```

### 2.2 Pipeline 索引文件

#### **model_index.json** (541B, 33行)
- 定义整个 Pipeline 的组成结构
- 指定每个组件的类型和来源
- 主要组件：
  ```json
  {
    "_class_name": "StableDiffusionPipeline",
    "_diffusers_version": "0.6.0",
    "text_encoder": ["transformers", "CLIPTextModel"],
    "tokenizer": ["transformers", "CLIPTokenizer"],
    "unet": ["diffusers", "UNet2DConditionModel"],
    "vae": ["diffusers", "AutoencoderKL"],
    "scheduler": ["diffusers", "PNDMScheduler"],
    "feature_extractor": ["transformers", "CLIPImageProcessor"]
  }
  ```

### 2.3 子模块详解

#### 2.3.1 Text Encoder（文本编码器）
**作用**：将文本提示词转换为条件向量，指导图像生成

- **config.json**
  - 定义 CLIP 文本编码器架构
  - 层数、注意力头数、隐藏层维度等参数

- **pytorch_model.bin**
  - CLIP 文本编码器的权重文件
  - 用于理解和编码文本提示

#### 2.3.2 Tokenizer（分词器）
**作用**：将输入文本转换为模型可处理的 token 序列

- **tokenizer_config.json**
  - CLIP 分词器配置
  - 最大序列长度、特殊标记等

- **vocab.json**
  - JSON 格式的词汇表
  - Token 到 ID 的映射字典

- **merges.txt**
  - BPE（字节对编码）合并规则
  - 定义子词单元的合并顺序

#### 2.3.3 UNet（去噪网络）
**作用**：扩散模型的核心，进行逐步去噪生成图像

- **config.json**
  - UNet 网络架构配置
  - 下采样/上采样块数量、通道数等

- **diffusion_pytorch_model.bin**
  - UNet 的权重文件
  - 通常是模型中最大的部分

#### 2.3.4 VAE（变分自编码器）
**作用**：在像素空间和潜在空间之间转换

- **config.json**
  - VAE 架构配置
  - 潜在空间维度、缩放因子等

- **diffusion_pytorch_model.bin**
  - VAE 编码器和解码器的权重
  - 编码器：图像 → 潜在表示
  - 解码器：潜在表示 → 图像

#### 2.3.5 Scheduler（调度器）
**作用**：控制扩散过程的噪声添加和去除策略

- **scheduler_config.json**
  - 调度算法配置
  - 如 PNDM（伪数值微分方法）
  - 步数、beta 范围等参数

#### 2.3.6 Feature Extractor（特征提取器）
**作用**：预处理输入图像（用于 img2img 模式）

- **preprocessor_config.json**
  - 图像预处理配置
  - 尺寸调整、归一化参数

### 2.4 完整权重文件

#### **v1-5-pruned-emaonly.safetensors** (4.0GB)
- SafeTensors 格式的完整模型权重
- 包含所有子模块的权重（UNet、VAE、Text Encoder）
- 优点：
  - 更安全（防止任意代码执行）
  - 加载速度快
  - 内存映射支持
- 可以替代各个子目录中的单独权重文件

---

## 三、其他复杂模型架构

除了 Pipeline 模型外，大模型领域还存在多种复杂的架构设计。这些架构各有特点，适用于不同的应用场景。

### 3.1 多模态融合模型（Multimodal Fusion Models）

#### 架构特点
将多种模态（文本、图像、音频等）的编码器融合在一起，通过共享的嵌入空间实现跨模态理解。

#### 典型代表：CLIP（Contrastive Language-Image Pre-training）

**文件结构**：
```
clip-model/
├── config.json                      # 整体配置
├── pytorch_model.bin                # 完整模型权重
├── text_model/                      # 文本编码器
│   ├── config.json
│   └── pytorch_model.bin
├── vision_model/                    # 视觉编码器
│   ├── config.json
│   └── pytorch_model.bin
├── projection/                      # 投影层
│   └── projection_weights.bin
├── tokenizer/                       # 文本分词器
└── preprocessor/                    # 图像预处理器
```

**架构特点**：
- **双编码器设计**：独立的文本和图像编码器
- **对比学习**：通过对比损失对齐两个模态
- **共享嵌入空间**：文本和图像映射到同一空间
- **模块化权重**：可以单独加载文本或视觉编码器

**应用场景**：
- 图文检索
- 零样本分类
- 文生图的文本理解
- 图生文的视觉理解

### 3.2 编码器-解码器模型（Encoder-Decoder Models）

#### 架构特点
包含独立的编码器和解码器，适合序列到序列任务。

#### 典型代表：T5（Text-to-Text Transfer Transformer）

**文件结构**：
```
t5-model/
├── config.json                      # 整体配置
├── pytorch_model.bin                # 完整权重
├── encoder/                         # 编码器
│   ├── config.json
│   └── pytorch_model.bin
├── decoder/                         # 解码器
│   ├── config.json
│   └── pytorch_model.bin
├── shared_embeddings.bin            # 共享嵌入层
├── tokenizer_config.json
├── spiece.model                     # SentencePiece 模型
└── generation_config.json           # 生成配置
```

**架构特点**：
- **独立的编码器-解码器**：分别处理输入和生成输出
- **共享嵌入**：编码器和解码器可能共享词嵌入层
- **交叉注意力**：解码器通过交叉注意力机制关注编码器输出
- **统一格式**：所有任务都转换为文本到文本

**应用场景**：
- 机器翻译
- 文本摘要
- 问答系统
- 代码生成

### 3.3 混合专家模型（Mixture of Experts, MoE）

#### 架构特点
使用多个"专家"子网络，根据输入动态选择激活哪些专家，实现更大的模型容量和更高的效率。

#### 典型代表：Switch Transformer、GLaM

**文件结构**：
```
moe-model/
├── config.json                      # MoE 配置
├── shared_layers/                   # 共享层
│   └── pytorch_model.bin
├── experts/                         # 专家网络
│   ├── expert_0/
│   │   └── pytorch_model.bin
│   ├── expert_1/
│   │   └── pytorch_model.bin
│   ├── expert_2/
│   │   └── pytorch_model.bin
│   └── ...                          # 可能有数十到数百个专家
├── router/                          # 路由网络
│   ├── config.json
│   └── pytorch_model.bin
└── tokenizer/
```

**架构特点**：
- **稀疏激活**：每次只激活部分专家，降低计算成本
- **路由机制**：动态决定激活哪些专家
- **专家并行**：不同专家可以分布在不同设备上
- **大规模参数**：总参数量巨大，但单次推理只用一部分

**关键配置字段**：
```json
{
  "num_experts": 128,
  "expert_capacity": 64,
  "top_k_experts": 2,
  "router_type": "learned",
  "load_balancing_loss_coef": 0.01
}
```

**应用场景**：
- 超大规模语言模型
- 多领域知识处理
- 需要高效推理的场景

### 3.4 适配器模型（Adapter Models）

#### 架构特点
在预训练模型中插入小型可训练模块（适配器），冻结主模型参数，只训练适配器。

#### 典型代表：LoRA（Low-Rank Adaptation）

**文件结构**：
```
base-model-with-lora/
├── base_model/                      # 基础模型（冻结）
│   ├── config.json
│   └── pytorch_model.bin
├── lora_adapters/                   # LoRA 适配器
│   ├── adapter_config.json          # 适配器配置
│   ├── lora_A.bin                   # 低秩分解矩阵 A
│   ├── lora_B.bin                   # 低秩分解矩阵 B
│   └── adapter_model.bin            # 完整适配器权重
├── peft_config.json                 # PEFT 配置
└── tokenizer/
```

**适配器配置示例**：
```json
{
  "peft_type": "LORA",
  "task_type": "CAUSAL_LM",
  "r": 8,                            # 秩
  "lora_alpha": 32,
  "lora_dropout": 0.1,
  "target_modules": ["q_proj", "v_proj"],
  "bias": "none"
}
```

**架构特点**：
- **参数效率**：只训练少量参数（通常 <1% 基础模型）
- **低秩分解**：W' = W + BA，其中 B 和 A 是低秩矩阵
- **可插拔性**：可以轻松切换不同的适配器
- **多任务支持**：为不同任务训练不同的适配器

**其他适配器类型**：
- **Prefix Tuning**：在输入序列前添加可训练前缀
- **Prompt Tuning**：优化软提示向量
- **Adapter Layers**：在 Transformer 层中插入小型网络

**应用场景**：
- 模型微调
- 多任务学习
- 个性化定制
- 资源受限环境

### 3.5 可控生成模型

#### 典型代表：ControlNet

**文件结构**：
```
controlnet-model/
├── base_model/                      # 原始 Stable Diffusion
│   ├── unet/
│   ├── vae/
│   └── text_encoder/
├── controlnet/                      # ControlNet 控制网络
│   ├── config.json
│   ├── control_net_weights.bin
│   ├── zero_conv_in.bin             # 零卷积输入
│   └── zero_conv_out.bin            # 零卷积输出
├── conditioning_encoder/            # 条件编码器
│   ├── edge_encoder.bin             # 边缘检测编码器
│   ├── pose_encoder.bin             # 姿态编码器
│   ├── depth_encoder.bin            # 深度图编码器
│   └── ...
└── model_index.json
```

**架构特点**：
- **并行分支**：ControlNet 是 UNet 的副本，接收额外的条件输入
- **零卷积**：使用零初始化的卷积层，确保初始时不影响原模型
- **条件注入**：将边缘、深度、姿态等条件信息注入生成过程
- **可组合性**：多个 ControlNet 可以组合使用

**应用场景**：
- 可控图像生成
- 图像编辑
- 结构保持的风格迁移

### 3.6 级联模型（Cascaded Models）

#### 架构特点
多个模型按顺序工作，前一个模型的输出作为后一个模型的输入，逐步提升质量。

#### 典型代表：Cascade Diffusion Models

**文件结构**：
```
cascade-model/
├── stage_1/                         # 第一阶段：低分辨率生成
│   ├── model_index.json
│   ├── unet/
│   ├── vae/
│   └── text_encoder/
├── stage_2/                         # 第二阶段：超分辨率
│   ├── model_index.json
│   ├── super_resolution_unet/
│   └── upsampler/
├── stage_3/                         # 第三阶段：进一步细化
│   ├── model_index.json
│   └── refinement_unet/
└── cascade_config.json              # 级联配置
```

**级联配置示例**：
```json
{
  "num_stages": 3,
  "resolutions": [64, 256, 1024],
  "stage_configs": [
    {"model_type": "text2img", "resolution": 64},
    {"model_type": "super_resolution", "scale_factor": 4},
    {"model_type": "refinement", "scale_factor": 4}
  ]
}
```

**应用场景**：
- 高分辨率图像生成
- 多阶段翻译
- 粗到精的生成任务

### 3.7 多任务学习模型（Multi-Task Learning）

#### 架构特点
一个模型同时学习多个相关任务，共享底层表示，任务特定的头部分别处理不同任务。

**文件结构**：
```
multi-task-model/
├── config.json                      # 多任务配置
├── shared_encoder/                  # 共享编码器
│   ├── config.json
│   └── pytorch_model.bin
├── task_heads/                      # 任务特定头部
│   ├── classification_head.bin
│   ├── qa_head.bin
│   ├── ner_head.bin
│   └── sentiment_head.bin
├── task_configs/                    # 各任务配置
│   ├── classification_config.json
│   ├── qa_config.json
│   └── ner_config.json
└── tokenizer/
```

**多任务配置示例**：
```json
{
  "tasks": ["classification", "ner", "qa", "sentiment"],
  "shared_layers": [0, 1, 2, 3, 4, 5],
  "task_specific_layers": {
    "classification": [6, 7],
    "ner": [6, 7, 8],
    "qa": [6, 7],
    "sentiment": [6]
  },
  "loss_weights": {
    "classification": 1.0,
    "ner": 0.8,
    "qa": 1.2,
    "sentiment": 0.5
  }
}
```

**应用场景**：
- 统一的 NLP 框架
- 资源共享
- 迁移学习

### 3.8 知识蒸馏模型（Teacher-Student Models）

#### 架构特点
大型教师模型指导小型学生模型学习，压缩模型同时保持性能。

**文件结构**：
```
distilled-model/
├── teacher_model/                   # 教师模型（可选，推理时不需要）
│   ├── config.json
│   └── pytorch_model.bin
├── student_model/                   # 学生模型
│   ├── config.json
│   └── pytorch_model.bin
├── distillation_config.json         # 蒸馏配置
└── tokenizer/
```

**蒸馏配置示例**：
```json
{
  "temperature": 2.0,
  "alpha": 0.5,
  "distillation_type": "soft",
  "teacher_model_path": "./teacher_model",
  "student_model_path": "./student_model",
  "layer_mapping": {
    "teacher_layer_0": "student_layer_0",
    "teacher_layer_6": "student_layer_3"
  }
}
```

**应用场景**：
- 模型压缩
- 边缘设备部署
- 推理加速

### 3.9 检索增强生成模型（Retrieval-Augmented Generation）

#### 典型代表：RAG

**文件结构**：
```
rag-model/
├── query_encoder/                   # 查询编码器
│   ├── config.json
│   └── pytorch_model.bin
├── generator/                       # 生成模型
│   ├── config.json
│   └── pytorch_model.bin
├── knowledge_base/                  # 知识库
│   ├── documents.index              # FAISS 索引
│   ├── embeddings.npy               # 文档嵌入
│   └── corpus.jsonl                 # 原始文档
├── retriever_config.json            # 检索配置
└── tokenizer/
```

**架构特点**：
- **检索组件**：从外部知识库检索相关信息
- **生成组件**：基于检索结果生成答案
- **动态知识**：可以更新知识库而无需重新训练
- **可解释性**：可以追溯到具体的检索来源

**应用场景**：
- 问答系统
- 知识密集型任务
- 需要实时信息的场景

### 3.10 分层模型（Hierarchical Models）

#### 架构特点
多层次的模型结构，每层处理不同粒度的信息。

**文件结构**：
```
hierarchical-model/
├── word_level/                      # 词级编码器
│   └── pytorch_model.bin
├── sentence_level/                  # 句级编码器
│   └── pytorch_model.bin
├── document_level/                  # 文档级编码器
│   └── pytorch_model.bin
├── hierarchical_config.json
└── tokenizer/
```

**应用场景**：
- 长文档理解
- 多尺度处理
- 层次化分类

---

## 四、文件类型详解

### 4.1 权重文件格式

| 格式 | 扩展名 | 特点 | 使用场景 |
|------|--------|------|----------|
| **PyTorch Binary** | `.bin` | PyTorch 标准格式，使用 pickle | PyTorch 生态系统 |
| **SafeTensors** | `.safetensors` | 安全、快速，无代码执行风险 | 推荐用于生产环境 |
| **TensorFlow H5** | `.h5` | Keras/TensorFlow 格式 | TensorFlow 生态系统 |
| **ONNX** | `.onnx` | 跨框架通用格式 | 跨平台部署 |

### 4.2 配置文件类型

#### 4.2.1 config.json
- **用途**：定义模型架构和超参数
- **关键字段**：
  - `architectures`: 模型类名
  - `hidden_size`: 隐藏层维度
  - `num_hidden_layers`: 层数
  - `num_attention_heads`: 注意力头数
  - `vocab_size`: 词汇表大小
  - `max_position_embeddings`: 最大序列长度
  - `torch_dtype`: 权重数据类型

#### 4.2.2 tokenizer_config.json
- **用途**：分词器行为配置
- **关键字段**：
  - `model_max_length`: 最大输入长度
  - `do_lower_case`: 是否转小写
  - `tokenizer_class`: 分词器类名
  - 特殊标记：`cls_token`, `sep_token`, `pad_token`, `unk_token`, `mask_token`

#### 4.2.3 preprocessor_config.json
- **用途**：图像/音频预处理配置
- **关键字段**：
  - `size`: 目标尺寸
  - `image_mean`: 归一化均值
  - `image_std`: 归一化标准差
  - `do_resize`: 是否调整大小
  - `do_normalize`: 是否归一化

### 4.3 词汇表文件

#### 4.3.1 vocab.txt
- 纯文本格式，每行一个 token
- 行号即为 token ID
- 常用于 BERT 系列模型

#### 4.3.2 vocab.json
- JSON 格式，token 到 ID 的映射字典
- 常用于 GPT、CLIP 等模型
- 示例：
  ```json
  {
    "hello": 123,
    "world": 456
  }
  ```

#### 4.3.3 merges.txt
- BPE 合并规则文件
- 每行一个字节对，按优先级排序
- 示例：
  ```
  h e
  he l
  hel lo
  ```

### 4.4 特殊文件

#### 4.4.1 tokenizer.json
- Hugging Face 快速分词器的完整序列化
- 包含所有分词逻辑、规则、后处理步骤
- 用 Rust 实现，速度快

#### 4.4.2 special_tokens_map.json
- 定义特殊标记的映射
- 常见特殊标记：
  - `[CLS]`: 序列开始标记（分类任务）
  - `[SEP]`: 序列分隔标记
  - `[PAD]`: 填充标记
  - `[UNK]`: 未知词标记
  - `[MASK]`: 掩码标记（预训练）

#### 4.4.3 model_index.json
- Pipeline 模型的组件索引
- 指定每个组件的库来源和类名
- 用于自动化加载复杂模型

---

## 五、最佳实践

### 5.1 文件管理

#### 必需文件
以 BLIP 模型为例，最小运行所需文件：
```
✓ config.json                    # 必需：模型架构
✓ pytorch_model.bin              # 必需：模型权重
✓ tokenizer_config.json          # 必需：分词器配置
✓ vocab.txt                      # 必需：词汇表
✓ preprocessor_config.json       # 必需：预处理配置
✗ tf_model.h5                    # 可选：仅 TensorFlow 需要
✗ tokenizer.json                 # 可选：快速分词器
✗ special_tokens_map.json        # 可选：大多数情况下可推断
```

#### Pipeline 模型必需文件
以 Stable Diffusion 为例：
```
✓ model_index.json               # 必需：Pipeline 定义
✓ text_encoder/                  # 必需：文本编码
✓ tokenizer/                     # 必需：分词
✓ unet/                          # 必需：去噪网络
✓ vae/                           # 必需：编解码
✓ scheduler/                     # 必需：调度策略
✗ feature_extractor/             # 可选：仅 img2img 需要
```

### 5.2 存储优化

#### 使用 SafeTensors
- 如果有 `.safetensors` 文件，可以删除对应的 `.bin` 文件
- SafeTensors 更安全、加载更快

#### 删除冗余格式
- 如果只用 PyTorch，删除 `tf_model.h5`
- 如果只用 TensorFlow，删除 `pytorch_model.bin`

#### 压缩存储
- 权重文件可以用 Git LFS 管理
- 考虑使用量化版本（如 INT8、FP16）减小文件大小

### 5.3 版本管理

#### Git LFS
```bash
# 追踪大文件
git lfs track "*.bin"
git lfs track "*.safetensors"
git lfs track "*.h5"
```

#### 版本记录
在 `config.json` 中记录版本信息：
- `transformers_version`: Transformers 库版本
- `_commit_hash`: 模型快照哈希
- `_diffusers_version`: Diffusers 库版本（如果适用）

### 5.4 加载模型

#### 单体模型加载（BLIP）
```python
from transformers import BlipProcessor, BlipForConditionalGeneration

# 从本地目录加载
model = BlipForConditionalGeneration.from_pretrained("./models/blip-image-captioning-base")
processor = BlipProcessor.from_pretrained("./models/blip-image-captioning-base")
```

#### Pipeline 模型加载（Stable Diffusion）
```python
from diffusers import StableDiffusionPipeline

# 从本地目录加载
pipe = StableDiffusionPipeline.from_pretrained(
    "./models/stable-diffusion-v1-5-img2img",
    torch_dtype=torch.float16
)
```

#### 使用 SafeTensors
```python
from safetensors.torch import load_file

# 加载 SafeTensors 格式
state_dict = load_file("v1-5-pruned-emaonly.safetensors")
```

### 5.5 安全性建议

1. **验证文件来源**
   - 只从可信源下载模型
   - 检查文件哈希值

2. **优先使用 SafeTensors**
   - 避免 pickle 反序列化的代码执行风险
   - 更快的加载速度

3. **隔离运行环境**
   - 使用虚拟环境或容器
   - 限制模型文件的访问权限

4. **定期更新**
   - 关注模型安全更新
   - 使用最新的库版本

---

## 六、常见问题

### Q1: config.json 丢失会怎样？
**A**: 模型无法加载。config.json 定义了模型架构，没有它程序不知道如何构建网络结构。

### Q2: 可以只用 vocab.txt，不用 tokenizer.json 吗？
**A**: 可以，但速度较慢。tokenizer.json 是优化后的快速版本，适合生产环境。

### Q3: Stable Diffusion 的 safetensors 文件和各子目录的 bin 文件有什么关系？
**A**: safetensors 包含了所有子模块的完整权重。如果使用 safetensors，可以不需要单独的 bin 文件。

### Q4: 如何减小模型体积？
**A**: 
- 使用量化（INT8、FP16）
- 模型蒸馏
- 模型剪枝
- 删除不需要的框架版本（如删除 tf_model.h5）

### Q5: 不同框架的权重文件可以互相转换吗？
**A**: 可以。Hugging Face 提供了转换工具：
```python
from transformers import TFAutoModel, AutoModel

# PyTorch -> TensorFlow
tf_model = TFAutoModel.from_pretrained("./model", from_pt=True)
tf_model.save_pretrained("./model")

# TensorFlow -> PyTorch  
pt_model = AutoModel.from_pretrained("./model", from_tf=True)
pt_model.save_pretrained("./model")
```

---

## 七、总结

### 核心要点
1. **权重文件**是模型的核心，包含训练后的参数
2. **配置文件**定义模型架构和行为
3. **分词器文件**处理文本输入
4. **预处理器文件**处理图像/音频输入
5. **Pipeline 模型**通过多个子模块协同工作
6. **复杂架构**根据不同应用场景有不同的组织形式

### 架构分类总结

| 架构类型 | 特点 | 典型代表 | 主要应用 |
|---------|------|---------|---------|
| **单体模型** | 所有组件在一个目录 | BERT, GPT | 基础 NLP 任务 |
| **Pipeline 模型** | 多个独立子模型组合 | Stable Diffusion | 图像生成 |
| **多模态融合** | 跨模态共享嵌入空间 | CLIP, BLIP | 图文理解 |
| **编码器-解码器** | 独立的输入输出处理 | T5, BART | 翻译、摘要 |
| **混合专家 (MoE)** | 稀疏激活的多专家系统 | Switch Transformer | 超大规模模型 |
| **适配器模型** | 参数高效微调 | LoRA, Adapter | 模型定制 |
| **可控生成** | 条件注入的生成控制 | ControlNet | 可控图像生成 |
| **级联模型** | 多阶段逐步精化 | Cascade Diffusion | 高分辨率生成 |
| **多任务学习** | 共享底层多头输出 | MTL Models | 统一 NLP 框架 |
| **知识蒸馏** | 教师-学生压缩 | DistilBERT | 模型压缩 |
| **检索增强** | 结合外部知识库 | RAG | 知识密集任务 |
| **分层模型** | 多粒度层次处理 | Hierarchical Models | 长文档理解 |

### 文件优先级
```
最重要：config.json + 权重文件 (.bin/.safetensors)
很重要：tokenizer 相关文件（分词器）
重要：preprocessor 相关文件（预处理）
可选：特殊标记映射、快速分词器等
```

### 选择建议

#### 按应用场景选择
- **基础 NLP 任务**：单体模型（BERT、GPT）
- **图像生成**：Pipeline 模型（Stable Diffusion）
- **跨模态理解**：多模态融合模型（CLIP、BLIP）
- **翻译/摘要**：编码器-解码器模型（T5、BART）
- **超大规模部署**：混合专家模型（MoE）
- **模型定制微调**：适配器模型（LoRA）
- **可控生成**：ControlNet 等可控模型
- **资源受限环境**：知识蒸馏模型（DistilBERT）
- **知识密集任务**：检索增强模型（RAG）

#### 按部署环境选择
- **生产环境**：优先使用 SafeTensors 格式
- **开发调试**：保留所有配置文件便于调试
- **边缘设备**：使用蒸馏或量化模型
- **云端服务**：可以使用完整的大规模模型
- **本地运行**：考虑使用适配器减少存储需求

---

**文档说明**:
- **基础示例**: BLIP (图生文) + Stable Diffusion v1.5 (图生图)
- **涵盖架构**: 单体模型、Pipeline 模型、多模态融合、编码器-解码器、MoE、适配器、可控生成、级联、多任务、知识蒸馏、检索增强、分层模型
- **适用范围**: NLP、CV、多模态应用
